---
title: ". "
title-slide-attributes:
  data-background-image: "plot/module-3-title-page.png"
  data-background-size: "cover"
format: 
  revealjs:
    theme: [simple, custom.scss]
    preview-links: true
    code-fold: false
    code-summary: "code"
    chalkboard: true
    slide-number: true
    footer: "Econ 149: Analytical and statistical packages 2"
    quiz:
      defaultCorrect: "Correct!"
      defaultIncorrect: "Incorrect!"
revealjs-plugins:
  - quiz
engine: knitr
from: markdown+emoji
editor: visual
---

```{r}
#| echo: false
#| include: false
knitr::opts_chunk$set(comment = "", 
                      collapse = TRUE,
                      fig.align = "center",
                      fig.width = 8,
                      fig.height = 7
                      )

## working directory
setwd("C:/Users/chris/Documents/Github-repository/econ149-lecture/module-3-regression")

## Libraries
library(tidyverse)
library(glue)
library(patchwork)
library(kableExtra)

# reading data


# setting the theme
theme_set(theme_bw(base_size = 18)) # Set theme for all ggplots

```

# Introduction to simple linear regression

## Simple linear regression

```{r}
#| fig-align: center
#| fig-height: 5
#| fig-width: 10

# Parameters for the equation
a <- 2  # Intercept
b <- 3  # Slope

# Generate data for the line
x <- seq(-10, 10, by = 0.5)
y <- a + b * x
data <- data.frame(x = x, y = y)

# Generate random points around the line
set.seed(42)  # For reproducibility
points <- data.frame(
  x = runif(30, min = -10, max = 10),  # Random x-values
  y = a + b * runif(30, min = -10, max = 10) + rnorm(30, sd = 5)  # Add noise to y
)

# Create plot
ggplot() +
  geom_line(data = data, aes(x = x, y = y), color = "blue", size = 1) +  # Line for y = a + bx
  geom_point(data = points, aes(x = x, y = y), color = "red", size = 2) +  # Random points
  annotate(
    "text", x = 5, y = 15, 
    label = paste("y =", a, "+", b, "x"), 
    color = "darkgreen", size = 5, hjust = 0
  ) +
  labs(
    caption = "Plot of y = a + bx with Scatter Points",
    x = "x",
    y = "y"
  ) +
  theme_minimal(base_size = 12) +
  theme(plot.caption = element_text(hjust = 0.5, margin = margin(t=15), size = 14))
```


## Simple linear regression

```{r}
knitr::include_graphics("plot/simle-linear-reg.png")
```

## Simple linear regression

::: callout-tip
## Example in R

A distributor of frozen desert pies wants to evaluate the effect of price to the demand of pie. Data are collected for 15 weeks.
:::

## Simple linear regression

::::: columns
::: {.column width="30%"}
Step 1: import dataset

```{r}
#| echo: true

## import synthetic data
df <- tibble(
  Week = 1:15,
  Pie_Sales = c(350, 460, 350, 430, 350, 380, 430, 470, 450, 490, 340, 300, 440, 450, 300),
  Price = c(5.50, 7.50, 8.00, 8.00, 6.80, 7.50, 4.50, 6.40, 7.00, 5.00, 7.20, 7.90, 5.90, 5.00, 7.00),
  Advertising = c(3.3, 3.3, 3.0, 4.5, 3.0, 4.0, 3.0, 3.7, 3.5, 4.0, 3.5, 3.2, 4.0, 3.5, 2.7)
)

## print dataset
head(df)

```
:::

::: {.column width="70%"}
Step 2: Create a scatter plot

```{r}
#| fig-align: center
#| fig-height: 6
#| fig-width: 8


df |> ggplot(aes(Price, Pie_Sales)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  scale_x_continuous(limits = c(4, 10)) +
  scale_y_continuous(limits = c(200, 500)) +
  theme_minimal(base_size = 14)
  
```
:::
:::::

## Simple linear regression

::::: columns
::: {.column width="50%"}
Step 3: Estimate the model

```{r}
#| echo: true

## estimating linear regression
model <- lm(Pie_Sales ~ Price, data = df)

## printing model summary
summary(model)
```
:::

::: {.column width="50%"}
Step 4: Interpret results

-   y-intercept (a): 558.28

    -   estimated average value of $y$ when all $x_i = 0$

-   slope (b): -24.03

    -   estimates the average value of y changes by $b_i$ units for each 1 unit increase in $x_i$ holding other variables constant.

    -   example: a 1 unit increase in price decreases the pie sales by 24.03 pies per week.
:::
:::::

## Multiple linear regression

-   a linear regression with one or more independent variable (explanatory variable), and one dependent variable (response variable).

-   multiple regression model

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + b_k x_k
$$

## Multiple linear regression

## Multiple linear regression

::: callout-tip
## Example in R

A distributor of frozen desert pies wants to evaluate the factors affecting the demand of pie. Data are collected for 15 weeks.
:::

## Multiple linear regression

::::: columns
::: {.column width="30%"}
Step 1: import dataset

```{r}
#| echo: true

## import synthetic data
df <- tibble(
  Week = 1:15,
  Pie_Sales = c(350, 460, 350, 430, 350, 380, 430, 470, 450, 490, 340, 300, 440, 450, 300),
  Price = c(5.50, 7.50, 8.00, 8.00, 6.80, 7.50, 4.50, 6.40, 7.00, 5.00, 7.20, 7.90, 5.90, 5.00, 7.00),
  Advertising = c(3.3, 3.3, 3.0, 4.5, 3.0, 4.0, 3.0, 3.7, 3.5, 4.0, 3.5, 3.2, 4.0, 3.5, 2.7)
)

## print dataset
head(df)

```
:::

::: {.column width="70%"}
Step 2: Create a scatter plot

```{r}
#| fig-align: center
#| fig-height: 6
#| fig-width: 8

library(plotly)

fig <- plot_ly(
  df, 
  x = ~Price, 
  y = ~Advertising, 
  z = ~Pie_Sales, 
  type = "scatter3d", 
  mode = "markers",
  marker = list(size = 5, color = ~Pie_Sales, colorscale = "Viridis", showscale = TRUE)
) %>%
  layout(
    title = "3D Scatter Plot: Pie Sales vs Price and Advertising",
    scene = list(
      xaxis = list(title = "Price"),
      yaxis = list(title = "Advertising"),
      zaxis = list(title = "Pie Sales")
    )
  )

# Display the plot
fig

  
```
:::
:::::

## Multiple linear regression

::::: columns
::: {.column width="50%"}
Step 3: Estimate the model

```{r}
#| echo: true

## estimating linear regression
model <- lm(Pie_Sales ~ Price + Advertising, data = df)

## printing model summary
summary(model)
```
:::

::: {.column width="50%"}
Step 4: Interpret results

-   $\beta_1$ (Price): -24.98

    -   pie sales will decrease, on average, by 24.98 pies per week for each 1 unit increase in selling price, net of the effects of changes due to advertising.

-   $\beta_2$ (Advertising): 74.13

    -   sales will increase, on average, by 74.13 pies per week for each \$1 increase in advertising, net of the effects of changes due to price.
:::
:::::

## Multiple linear regression

<br>

::::: columns
::: {.column width="30%"}
```{r}
#| echo: true
#| eval: false

library(sjPlot)

tab_model(model, 
          p.style = "stars", 
          show.ci = FALSE, 
          show.se = T, 
          show.stat = TRUE)
```
:::

::: {.column width="70%"}
```{r}

library(sjPlot)

tab_model(model, 
          p.style = "stars", 
          show.ci = FALSE, 
          show.se = T, 
          show.stat = TRUE)
```
:::
:::::

# Check-up quiz

## What is the primary goal of linear regression analysis? {.quiz-question}

-   To determine the strength of the relationship between two categorical variables.

-   [To predict the value of a dependent variable based on one or more independent variables]{.correct}

-   To compare the means of two or more groups.

-   To analyze the frequency of occurrences within categories.

## In simple linear regression, what does the slope of the regression line represent? {.quiz-question}

-   The average value of the dependent variable.

-   [The change in the dependent variable for a one-unit increase in the independent variable]{.correct}

-   The correlation between the two variables.

-   The predicted value of the dependent variable when the independent variable is zero.

## How does multiple linear regression differ from simple linear regression? {.quiz-question}

-   Multiple linear regression uses only one independent variable.

-   [Multiple linear regression uses two or more independent variables]{.correct}

-   Multiple linear regression analyzes categorical variables.

-   Multiple linear regression does not involve a dependent variable.

## What is the coefficient of determination (R-squared) in the context of regression analysis? {.quiz-question}

-   [A measure of the strength of the linear relationship between the variables]{.correct}

-   The probability of making a correct prediction.

-   The difference between the observed and predicted values.

-   he slope of the regression line.

## Multiple coefficient of determination (R-squared)

- **R-squared ($R^2$)**

  - reports the proportion of total variation of in $y$ explained by all $x$ variables taken together

$$
R^2 = \frac{\text{SSR}}{SST} = \frac{\text{Sum of squares regression}}{\text{Total sum of squares}}
$$


## Multiple coefficient of determination (R-squared)

- **Adjusted R-squared ($R^2$)**

  - $R^2$ never decreases when new $x$ variable is added to the model.
  - This can be disadvantage when comparing models
  

<br>


:::: {.callout-warning}
## What is the effect of adding a new variable?

- We lose a degree of freedom when a new $x$ variable is added.
- Did the new $x$ variable add enough explanatory power to offset the loss of one degree of freedom?

::::


## Multiple coefficient of determination (R-squared)

:::: {.callout-note}

## **Adjusted R-squared ($R^2$)**

$$
R^2_A = 1 - (1 - R^2)(\frac{n-1}{n-k-1})
$$

- where
  - $n$ = sample size
  - $k$ = number of independent variables

::::

- 
  - shows the proportion of variation in $y$ explained by all $x$ variables adjusted for the number of $x$ variables used.
  
  - where excessive use of unimportant independent variables
  
  - smaller then $R^2$
  
  - useful in comparing among models
  
  


# Diagnostic tests


## Linearity assumption

- 

  - linear regression model relates the outcome to the predictors via a linear fashion.
  
  - departure from linearity can be checked by using a scatter plot and a line overlaid to the plots
  
  - if linearity is not satisfied, transformation may be needed
  
  
## Linearity assumption


**insert plot**


## Normality of errors

-

  - confidence intervals for regression and related hypothesis tests are based on the assumption that the coeffcient estimates have normal distribution.
  


## Homoscedasticity of error variance


## Independence of errors


## Non-multicollinearity


## 












# 

```{r}
knitr::include_graphics("plot/econ149-hex-logo.png")
```
